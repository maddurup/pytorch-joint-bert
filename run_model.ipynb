{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 490,
   "id": "8227a9d2-3684-4847-a5ae-a0cadc7a02c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seqeval\n",
    "# transformers\n",
    "# seqeval\n",
    "# pytorch-crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "556d1042-a905-4b61-a61d-ddfcabbe688c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 seqeval.__version__                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span>module <span style=\"color: #008000; text-decoration-color: #008000\">'seqeval'</span> has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'__version__'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 seqeval.__version__                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0mmodule \u001b[32m'seqeval'\u001b[0m has no attribute \u001b[32m'__version__'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seqeval.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "e8961795-812d-4f21-b62f-1de82c4e61e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python main.py --task katanemo \\\n",
    "#                   --model_type bert \\\n",
    "#                   --model_dir katanemo_model \\\n",
    "#                   --save_steps 10 \\\n",
    "#                   --do_train --do_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "739d6ce2-6173-4bdd-9861-030ace49cd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: main.py [-h] --task TASK --model_dir MODEL_DIR [--data_dir DATA_DIR]\n",
      "               [--intent_label_file INTENT_LABEL_FILE]\n",
      "               [--slot_label_file SLOT_LABEL_FILE] [--model_type MODEL_TYPE]\n",
      "               [--seed SEED] [--train_batch_size TRAIN_BATCH_SIZE]\n",
      "               [--eval_batch_size EVAL_BATCH_SIZE] [--max_seq_len MAX_SEQ_LEN]\n",
      "               [--learning_rate LEARNING_RATE]\n",
      "               [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
      "               [--weight_decay WEIGHT_DECAY]\n",
      "               [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "               [--adam_epsilon ADAM_EPSILON] [--max_grad_norm MAX_GRAD_NORM]\n",
      "               [--max_steps MAX_STEPS] [--warmup_steps WARMUP_STEPS]\n",
      "               [--dropout_rate DROPOUT_RATE] [--logging_steps LOGGING_STEPS]\n",
      "               [--save_steps SAVE_STEPS] [--do_train] [--do_eval] [--no_cuda]\n",
      "               [--ignore_index IGNORE_INDEX] [--slot_loss_coef SLOT_LOSS_COEF]\n",
      "               [--use_crf] [--slot_pad_label SLOT_PAD_LABEL]\n",
      "main.py: error: argument --slot_pad_label: expected one argument\n"
     ]
    }
   ],
   "source": [
    "!python main.py --task katanemo \\\n",
    "                  --model_type bert \\\n",
    "                  --model_dir katanemo_model \\\n",
    "                  --do_train --do_eval --num_train_epochs 30 --logging_steps 3 \\\n",
    "                  --save_steps 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "69391a9f-6532-4c3c-b566-fe5a3c2e87a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import predict\n",
    "from utils import init_logger, load_tokenizer, get_intent_labels, get_slot_labels, MODEL_CLASSES\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "8bab04b0-83de-4fcc-b124-107a24075c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args(pred_config):\n",
    "    return torch.load(os.path.join(pred_config.model_dir, 'training_args.bin'))\n",
    "\n",
    "def process_lines(lines_to_pred):\n",
    "    lines = []\n",
    "    for line in lines_to_pred:\n",
    "        line = line.strip()\n",
    "        words = line.split()\n",
    "        lines.append(words)\n",
    "    \n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "d5fe0839-4410-4aa5-b6d5-b625d6b64131",
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    task = 'katanemo'\n",
    "    model_dir = f'./{task}_model'\n",
    "    data_dir = './data/'\n",
    "    intent_label_file = 'intent_label.txt'\n",
    "    slot_label_file = 'slot_label.txt'\n",
    "    batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "34c87f03-8533-4b49-8fe7-b3e740773c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(task='katanemo', model_dir='katanemo_model', data_dir='./data', intent_label_file='intent_label.txt', slot_label_file='slot_label.txt', model_type='bert', seed=1234, train_batch_size=32, eval_batch_size=64, max_seq_len=50, learning_rate=5e-05, num_train_epochs=50.0, weight_decay=0.0, gradient_accumulation_steps=1, adam_epsilon=1e-08, max_grad_norm=1.0, max_steps=-1, warmup_steps=0, dropout_rate=0.1, logging_steps=3, save_steps=10, do_train=True, do_eval=True, no_cuda=False, ignore_index=0, slot_loss_coef=1.0, use_crf=False, slot_pad_label='PAD', model_name_or_path='bert-base-uncased')"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args = get_args(pred_config = args)\n",
    "model_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "f1cb6261-b699-4082-8d10-68d7874b8498",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_label_lst = get_intent_labels(args)\n",
    "slot_label_lst = get_slot_labels(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "b52b9050-b383-46fa-812f-da9a6cb69776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PAD',\n",
       " 'UNK',\n",
       " 'O',\n",
       " 'B-count_what',\n",
       " 'I-count_what',\n",
       " 'B-entity_type',\n",
       " 'I-entity_type',\n",
       " 'B-list_what',\n",
       " 'B-time_frame',\n",
       " 'I-time_frame']"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_slot_labels(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "d61cb539-0676-48ff-b6d8-9d7946cf4431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_loaded\n"
     ]
    }
   ],
   "source": [
    "model = MODEL_CLASSES['bert'][1].from_pretrained(args.model_dir, args=get_args(pred_config = args),\n",
    "                                                                  intent_label_lst=get_intent_labels(args),\n",
    "                                                                  slot_label_lst=get_slot_labels(args))\n",
    "model.eval()\n",
    "print('model_loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "1a5cac3a-4710-4d38-8328-da2c84d648ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert input file to TensorDataset\n",
    "pad_token_label_id = model_args.ignore_index\n",
    "tokenizer = load_tokenizer(model_args)\n",
    "# lines = read_input_file(pred_config)\n",
    "lines_to_pred = [\"how many devices have high network peaks?\", \n",
    "                \"Which network had major discards or errors?\",\n",
    "                \"Are there any drops in network over the last 10 months\"]\n",
    "# lines_to_pred = [\"show flights saturday evening from st. louis to burbank\", \n",
    "#                  \"which flights travel from las vegas to los angeles california and arrive on april ninth between 4 and 5 pm?\"]\n",
    "lines = process_lines(lines_to_pred)\n",
    "dataset = predict.convert_input_file_to_tensor_dataset(lines, args, model_args, tokenizer, pad_token_label_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0983a5-f2c8-426d-b7eb-35d102c0c8d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "0f9ffd62-c326-44f7-adeb-033e4b6db419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "sampler = SequentialSampler(dataset)\n",
    "data_loader = DataLoader(dataset, sampler=sampler, batch_size=args.batch_size)\n",
    "\n",
    "all_slot_label_mask = None\n",
    "intent_preds = None\n",
    "slot_preds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "0732c0e5-aec0-4f13-bb38-cbf40a1e9346",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "2edcae26-16e9-4c8b-9c13-29f1710a31b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  2.61it/s]\n"
     ]
    }
   ],
   "source": [
    "for batch in tqdm(data_loader, desc=\"Predicting\"):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    with torch.no_grad():\n",
    "        inputs = {\"input_ids\": batch[0],\n",
    "                  \"attention_mask\": batch[1],\n",
    "                  \"intent_label_ids\": None,\n",
    "                  \"slot_labels_ids\": None}\n",
    "        if model_args.model_type != \"distilbert\":\n",
    "            inputs[\"token_type_ids\"] = batch[2]\n",
    "        outputs = model(**inputs)\n",
    "        _, (intent_logits, slot_logits) = outputs[:2]\n",
    "\n",
    "        # Intent Prediction\n",
    "        if intent_preds is None:\n",
    "            intent_preds = intent_logits.detach().cpu().numpy()\n",
    "        else:\n",
    "            intent_preds = np.append(intent_preds, intent_logits.detach().cpu().numpy(), axis=0)\n",
    "\n",
    "        # Slot prediction\n",
    "        if slot_preds is None:\n",
    "            if model_args.use_crf:\n",
    "                # decode() in `torchcrf` returns list with best index directly\n",
    "                slot_preds = np.array(model.crf.decode(slot_logits))\n",
    "            else:\n",
    "                slot_preds = slot_logits.detach().cpu().numpy()\n",
    "            all_slot_label_mask = batch[3].detach().cpu().numpy()\n",
    "        else:\n",
    "            if model_args.use_crf:\n",
    "                slot_preds = np.append(slot_preds, np.array(model.crf.decode(slot_logits)), axis=0)\n",
    "            else:\n",
    "                slot_preds = np.append(slot_preds, slot_logits.detach().cpu().numpy(), axis=0)\n",
    "            all_slot_label_mask = np.append(all_slot_label_mask, batch[3].detach().cpu().numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "bec80f6f-a7c5-41e3-9f5d-d7c1953d2795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slot_label_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "ae214797-1176-466f-85e8-31cbe2265aed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<fact_count> -> how many devices have high network peaks? -> {'B-entity_type': ['devices', 'network']}\n",
      "\n",
      "<fact_list> -> Which network had major discards or errors? -> {'B-entity_type': ['network']}\n",
      "\n",
      "<time_series> -> Are there any drops in network over the last 10 months -> {'B-entity_type': ['network'], 'I-time_frame': ['months']}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "intent_preds = np.argmax(intent_preds, axis=1)\n",
    "\n",
    "if not model_args.use_crf:\n",
    "    slot_preds = np.argmax(slot_preds, axis=2)\n",
    "\n",
    "slot_label_map = {i: label for i, label in enumerate(slot_label_lst)}\n",
    "slot_preds_list = [[] for _ in range(slot_preds.shape[0])]\n",
    "\n",
    "for i in range(slot_preds.shape[0]):\n",
    "    for j in range(slot_preds.shape[1]):\n",
    "        if all_slot_label_mask[i, j] != pad_token_label_id:\n",
    "            slot_preds_list[i].append(slot_label_map[slot_preds[i][j]])\n",
    "\n",
    "# Write to output file\n",
    "\n",
    "for words, slot_preds, intent_pred in zip(lines, slot_preds_list, intent_preds):\n",
    "    line = \"\"\n",
    "    entity_dict = collections.defaultdict(list)\n",
    "    for word, pred in zip(words, slot_preds):\n",
    "        if pred == 'O':\n",
    "            line = line + word + \" \"\n",
    "        else:\n",
    "            # line = line + \"[{}:{}] \".format(word, pred)\n",
    "            entity_dict[pred].append(word)\n",
    "    # print(\"<{}> -> {} -> {}\\n\".format(intent_label_lst[intent_pred], \" \".join(words), line.strip()))\n",
    "    print(\"<{}> -> {} -> {}\\n\".format(intent_label_lst[intent_pred], \" \".join(words), dict(entity_dict)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "id": "9418b569-ec26-4f1b-a79e-b12bba394bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'B-entity_type': ['network'], 'I-time_frame': ['months'], 1: [], 0: []}"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(entity_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "id": "38fd5643-ee25-4f7e-a9d9-079bef24e36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<atis_flight> -> show flights [saturday:B-depart_date.day_name] [evening:B-depart_time.period_of_day] from [st.:B-fromloc.city_name] [louis:I-fromloc.city_name] to [burbank:B-toloc.city_name]\n",
      "\n",
      "<atis_flight> -> which flights travel from [las:B-fromloc.city_name] [vegas:I-fromloc.city_name] to [los:B-toloc.city_name] [angeles:I-toloc.city_name] [california:B-toloc.state_name] and arrive on [april:B-arrive_date.month_name] [ninth:B-arrive_date.day_number] between [4:B-arrive_time.start_time] and [5:B-arrive_time.end_time] [pm?:I-arrive_time.end_time]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "intent_preds = np.argmax(intent_preds, axis=1)\n",
    "\n",
    "if not model_args.use_crf:\n",
    "    slot_preds = np.argmax(slot_preds, axis=2)\n",
    "\n",
    "slot_label_map = {i: label for i, label in enumerate(slot_label_lst)}\n",
    "slot_preds_list = [[] for _ in range(slot_preds.shape[0])]\n",
    "\n",
    "for i in range(slot_preds.shape[0]):\n",
    "    for j in range(slot_preds.shape[1]):\n",
    "        if all_slot_label_mask[i, j] != pad_token_label_id:\n",
    "            slot_preds_list[i].append(slot_label_map[slot_preds[i][j]])\n",
    "\n",
    "for words, slot_preds, intent_pred in zip(lines, slot_preds_list, intent_preds):\n",
    "    line = \"\"\n",
    "    for word, pred in zip(words, slot_preds):\n",
    "        if pred == 'O':\n",
    "            line = line + word + \" \"\n",
    "        else:\n",
    "            line = line + \"[{}:{}] \".format(word, pred)\n",
    "\n",
    "    print(\"<{}> -> {}\\n\".format(intent_label_lst[intent_pred], line.strip()))\n",
    "        \n",
    "# # Write to output file\n",
    "# with open(pred_config.output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#     for words, slot_preds, intent_pred in zip(lines, slot_preds_list, intent_preds):\n",
    "#         line = \"\"\n",
    "#         for word, pred in zip(words, slot_preds):\n",
    "#             if pred == 'O':\n",
    "#                 line = line + word + \" \"\n",
    "#             else:\n",
    "#                 line = line + \"[{}:{}] \".format(word, pred)\n",
    "#         f.write(\"<{}> -> {}\\n\".format(intent_label_lst[intent_pred], line.strip()))\n",
    "\n",
    "# logger.info(\"Prediction Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "bdf42782-302c-4e00-b775-29c1ae660aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type'],\n",
       " ['B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type'],\n",
       " ['B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type',\n",
       "  'B-entity_type']]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slot_preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "f8f8382d-23c2-4cb3-885c-e8f78f3f8ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for words, slot_preds, intent_pred in zip(lines, slot_preds_list, intent_preds):\n",
    "    line = \"\"\n",
    "    for word, pred in zip(words, slot_preds):\n",
    "        if pred == 'O':\n",
    "            line = line + word + \" \"\n",
    "        else:\n",
    "            line = line + \"[{}:{}] \".format(word, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "ef6a1ae0-6472-44a4-908d-1246859f6ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['show',\n",
       "  'flights',\n",
       "  'saturday',\n",
       "  'evening',\n",
       "  'from',\n",
       "  'st.',\n",
       "  'louis',\n",
       "  'to',\n",
       "  'burbank'],\n",
       " ['which',\n",
       "  'flights',\n",
       "  'travel',\n",
       "  'from',\n",
       "  'las',\n",
       "  'vegas',\n",
       "  'to',\n",
       "  'los',\n",
       "  'angeles',\n",
       "  'california',\n",
       "  'and',\n",
       "  'arrive',\n",
       "  'on',\n",
       "  'april',\n",
       "  'ninth',\n",
       "  'between',\n",
       "  '4',\n",
       "  'and',\n",
       "  '5',\n",
       "  'pm?']]"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "df1dc353-1e81-40ec-9f63-5369c694b451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.0772, -1.0156, -0.3700, -0.3498, -0.3873,  3.2950, -0.6526, -0.3704,\n",
       "        -0.6510, -0.4977])"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slot_logits[2][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "c0e7c6c6-3bdd-4d46-abd0-44dd8d41ae96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['time_series', 'fact_count', 'fact_list', 'UNK']"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intent_label_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "f08538f0-3507-4daf-8a87-09cfefb4bbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Are B-entity_type\n",
      "there B-entity_type\n",
      "any B-entity_type\n",
      "drops B-entity_type\n",
      "in B-entity_type\n",
      "network B-entity_type\n",
      "over B-entity_type\n",
      "the B-entity_type\n",
      "last B-entity_type\n",
      "10 B-entity_type\n",
      "months B-entity_type\n"
     ]
    }
   ],
   "source": [
    "for word, pred in zip(words, slot_preds):\n",
    "    print(word, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "36a78737-6952-4cfe-b60c-5b27a0fbcd00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_args.use_crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8271f7bb-3f93-47d3-9ed9-cdeb8458f688",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
